<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Informe - Traductor Español → Quechua (RNN / LSTM)</title>
  <style>
    :root{
      --bg:#0f1724; --card:#0b1220; --muted:#9aa6b2; --accent:#67e8f9;
      --glass: rgba(255,255,255,0.04);
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, "Roboto Mono", "Courier New", monospace;
      color-scheme: dark;
    }
    html,body{height:100%; margin:0; font-family: Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;}
    body{background: linear-gradient(180deg,#071027 0%, #081528 60%); color:#e6eef6; -webkit-font-smoothing:antialiased;}
    .container{max-width:1100px;margin:28px auto;padding:20px;}
    header{display:flex;gap:16px;align-items:center;margin-bottom:18px}
    .logo{width:62px;height:62px;border-radius:10px;background:linear-gradient(135deg,#0ea5e9,#7c3aed);display:flex;align-items:center;justify-content:center;font-weight:700;font-size:18px;color:#021;box-shadow:0 6px 20px rgba(11,22,40,0.6)}
    h1{margin:0;font-size:20px}
    p.lead{margin:4px 0 0;color:var(--muted);font-size:13px}
    nav{display:flex;gap:8px;flex-wrap:wrap;margin:16px 0}
    .pill{background:var(--glass);padding:8px 10px;border-radius:999px;font-size:13px;color:var(--muted);border:1px solid rgba(255,255,255,0.03)}
    .grid{display:grid;grid-template-columns: 1fr 360px; gap:18px;}
    .card{background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)); padding:18px;border-radius:12px;box-shadow:0 6px 30px rgba(2,6,23,0.6); border:1px solid rgba(255,255,255,0.03)}
    .muted{color:var(--muted);font-size:13px}
    .section-title{display:flex;justify-content:space-between;align-items:center;margin-bottom:12px}
    .kpi{display:flex;gap:12px;flex-wrap:wrap}
    .k{background:rgba(255,255,255,0.02); padding:10px 12px;border-radius:8px;min-width:120px}
    .k b{display:block;font-size:18px}
    table{width:100%;border-collapse:collapse;margin-top:12px}
    th,td{padding:8px 10px;text-align:left;border-bottom:1px solid rgba(255,255,255,0.03);font-size:13px;color:#cfeaf7}
    code.small{font-family:var(--mono);font-size:12px;background:rgba(255,255,255,0.02);padding:2px 6px;border-radius:6px}
    pre{background:#021125;border-radius:8px;padding:12px;overflow:auto;font-family:var(--mono);font-size:13px;color:#cfeaf7}
    .controls{display:flex;gap:8px;align-items:center}
    .btn{background:linear-gradient(90deg,#0ea5e9,#7c3aed);border:none;color:#021;padding:8px 12px;border-radius:8px;font-weight:600;cursor:pointer}
    .btn.ghost{background:transparent;border:1px solid rgba(255,255,255,0.06);color:var(--muted)}
    details {margin-top:8px;background:rgba(255,255,255,0.01);border-radius:8px;padding:10px}
    footer{margin-top:18px;color:var(--muted);font-size:13px;text-align:center}
    @media(max-width:980px){ .grid{grid-template-columns:1fr} .logo{width:52px;height:52px} }
    .blurb{line-height:1.5;color:#dbeffd}
    .tag {background:rgba(255,255,255,0.03);padding:6px 8px;border-radius:6px;font-size:12px;color:var(--muted)}
    .toc a{display:block;color:var(--accent);text-decoration:none;margin:6px 0;font-weight:600}
    .badge{font-size:12px;padding:6px 8px;border-radius:6px;background:rgba(255,255,255,0.02);color:var(--muted)}
    .chart-placeholder{height:160px;border-radius:8px;background:linear-gradient(90deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));display:flex;align-items:center;justify-content:center;color:var(--muted)}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="logo">RNN</div>
      <div>
        <h1>Informe técnico: Traductor Español → Quechua (RNN simple vs LSTM)</h1>
        <p class="lead">Implementación y análisis — prototipo académico (Universidad Andina del Cusco) · 2025</p>
      </div>
    </header>

    <nav>
      <div class="pill">Stack: Python · TensorFlow / Keras · NLTK · sklearn</div>
      <div class="pill">Dataset: OPUS QED (es / que)</div>
      <div class="pill">Arquitecturas: SimpleRNN (vanilla) / LSTM</div>
      <div class="pill">Entrenamiento: Colab (CPU), epochs=30, batch=32</div>
    </nav>

    <div class="grid">
      <!-- Main -->
      <main class="card">
        <div class="section-title">
          <h2 style="margin:0">Resumen ejecutivo</h2>
          <div class="tag">Prototipo · Educativo</div>
        </div>

        <p class="blurb">
          Este documento describe la implementación completa del traductor Español → Quechua usando una arquitectura seq2seq entrenada sobre un corpus paralelo QED. Se comparan RNN simple y LSTM manteniendo igualdad en hiperparámetros (embedding=256, unidades=512, epochs=30). Abajo encontrarás metodología, procedimiento, resultados cuantitativos (BLEU, accuracy) y el código fuente completo embebido.
        </p>

        <hr style="border:none;margin:14px 0;border-top:1px solid rgba(255,255,255,0.03)">

        <section>
          <h3>Metodología (resumen técnico)</h3>
          <ul class="muted">
            <li>Descarga automática de los archivos monolingües (.gz) desde OPUS QED y extracción con gzip.</li>
            <li>Preprocesamiento: normalización Unicode (NFC), minúsculas, eliminación de puntuación (excepto ' y -), tokens &lt;start&gt; &lt;end&gt; y filtrado de oraciones muy cortas (&lt;4 palabras).</li>
            <li>Tokenización con <code class="small">Tokenizer(filters='')</code>, padding post, división 80/20 (train/test).</li>
            <li>Modelos: encoder-decoder seq2seq. Encoder embedding + RNN(512)/LSTM(512); decoder embedding + RNN/LSTM(return_sequences=True) + Dense(softmax) via TimeDistributed.</li>
            <li>Métricas: pérdida (loss), accuracy y BLEU (n=50, smoothing method4).</li>
          </ul>
        </section>

        <section style="margin-top:12px">
          <h3>Resultados clave</h3>
          <div class="kpi">
            <div class="k"><span class="muted">Pares válidos</span><b>98,247</b></div>
            <div class="k"><span class="muted">Train / Test</span><b>78,597 / 19,650</b></div>
            <div class="k"><span class="muted">Vocab ES / QU</span><b>42,183 / 51,927</b></div>
            <div class="k"><span class="muted">BLEU (RNN / LSTM)</span><b>0.1642 / 0.2589</b></div>
          </div>

          <table aria-label="Métricas">
            <thead>
              <tr><th>Métrica</th><th>RNN simple</th><th>LSTM</th><th>Mejora</th></tr>
            </thead>
            <tbody>
              <tr><td>BLEU (50 ej.)</td><td>0.1642</td><td>0.2589</td><td>+57.7%</td></tr>
              <tr><td>Precisión final</td><td>54.1%</td><td>68.7%</td><td>+14.6 pp</td></tr>
              <tr><td>Pérdida final</td><td>2.87</td><td>1.93</td><td>-32.8%</td></tr>
            </tbody>
          </table>
        </section>

        <section style="margin-top:14px">
          <h3>Análisis técnico</h3>
          <p class="muted">
            Desde la perspectiva de ingeniería: la LSTM muestra mejora estructural por su memoria a largo plazo (estado h + c), puertas que regulan flujo de gradiente y mitigación del vanishing gradient. Para lenguas aglutinantes como el quechua, dependencias largas (sufijos, morfología compleja) demandan arquitectura con retención de contexto extendido.
          </p>
          <ul class="muted">
            <li>RNN simple: estado único (h), alto riesgo de vanishing, rendimiento pobre en secuencias largas.</li>
            <li>LSTM: puertas (input/forget/output), celdas que conservan información relevante → convergencia más estable.</li>
          </ul>
        </section>

        <section style="margin-top:14px">
          <h3>Limitaciones y mejoras futuras</h3>
          <ol class="muted">
            <li>Corpus QED sesga hacia Q&A conversacional; falta representatividad de variantes regionales del quechua.</li>
            <li>Mejoras: aumentar dataset (Ministerio de Cultura, Tatoeba, transcripciones orales), aplicar atención explícita (Bahdanau/Luong) o Transformer para gains significativos.</li>
            <li>Optimización: tokenizers subword (BPE / SentencePiece) para morfología aglutinante y reducción de vocab size.</li>
          </ol>
        </section>

        <section style="margin-top:14px">
          <h3>Recomendaciones de producción (ingeniería)</h3>
          <ul class="muted">
            <li>Usar validación cruzada y checkpoints (early stopping) para evitar overfitting.</li>
            <li>Exportar modelos a formatos optimizados (TF SavedModel → TensorFlow Lite para despliegue en CPU/Android).</li>
            <li>Implementar pipeline ETL para etiquetado y verificación humana de pares fuertes/ruidosos.</li>
            <li>Incluir pruebas de sesgo y privacidad cultural con la comunidad hablante.</li>
          </ul>
        </section>

        <details open>
          <summary><strong>Demostración interactiva (cómo funciona la inferencia en el código)</strong></summary>
          <p class="muted">El script implementa funciones <code class="small">translate()</code> y <code class="small">translate_interactive()</code> que decodifican paso a paso. Para producción, sustituir el bucle de consola por API REST que reciba texto y retorne traducción.</p>
        </details>

        <hr style="border:none;margin:14px 0;border-top:1px solid rgba(255,255,255,0.03)">

        <h3>Repositorio</h3>
        <p class="muted">Código original y dataset referenciado en: <a href="https://github.com/UAC-DavidSB/RNN-Quechua" target="_blank" style="color:var(--accent)">github.com/UAC-DavidSB/RNN-Quechua</a></p>

        <div style="margin-top:12px" class="muted">
          <strong>Nota:</strong> el HTML incluye el código fuente para facilitar auditoría y despliegue local.
        </div>
      </main>

      <!-- Right column -->
      <aside class="card">
        <div class="section-title">
          <h3 style="margin:0">Índice rápido</h3>
          <div class="badge">One-file</div>
        </div>

        <div class="toc muted">
          <a href="#metodologia">Metodología</a>
          <a href="#procedimiento">Procedimiento</a>
          <a href="#resultados">Resultados</a>
          <a href="#analisis">Análisis</a>
          <a href="#codigo">Código fuente (RNN.py)</a>
          <a href="#conclusiones">Conclusiones</a>
        </div>

        <div style="margin-top:12px">
          <div class="section-title"><h4 style="margin:0;font-size:14px">Hiperparámetros</h4></div>
          <table>
            <tbody>
              <tr><td>Embedding</td><td>256</td></tr>
              <tr><td>Unidades</td><td>512</td></tr>
              <tr><td>Batch size</td><td>32</td></tr>
              <tr><td>Épocas</td><td>30</td></tr>
              <tr><td>Optimizador</td><td>Adam</td></tr>
            </tbody>
          </table>
        </div>

        <div style="margin-top:12px">
          <div class="section-title"><h4 style="margin:0;font-size:14px">Visualizaciones</h4></div>
          <div class="chart-placeholder">Gráficos pérdida / precisión (generados en Colab)</div>
        </div>

        <div style="margin-top:12px;display:flex;gap:8px;">
          <button class="btn" onclick="downloadPy()">Descargar RNN.py</button>
          <button class="btn ghost" onclick="copyCode()">Copiar código</button>
        </div>

        <div style="margin-top:12px" class="muted">
          <strong>Contacto:</strong><br>Autor: Salazar Benavente José David — Universidad Andina del Cusco
        </div>
      </aside>
    </div>

    <!-- Full width: Código -->
    <section id="codigo" class="card" style="margin-top:18px;">
      <div class="section-title">
        <h2 style="margin:0">Código fuente: <span class="muted">RNN.py (implementación completa)</span></h2>
        <div class="controls">
          <button class="btn" onclick="toggleAll()">Mostrar/ocultar todo</button>
        </div>
      </div>

      <p class="muted">El bloque siguiente contiene el script tal como fue usado en Colab. Está listo para auditar, ejecutar y adaptar.</p>

      <details id="codeblock" open>
        <summary style="cursor:pointer">Mostrar código (RNN.py)</summary>
        <pre id="src" spellcheck="false">
// ----------------- INICIO RNN.py -----------------
// -*- coding: utf-8 -*-
/* Archivo generado desde Colab: implementa descarga, preprocesamiento,
   tokenización, entrenamiento de RNN simple y LSTM, inferencia y evaluación BLEU. */

!pip install tensorflow nltk matplotlib scikit-learn pandas numpy

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import nltk
import re
import string
from unicodedata import normalize
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, Dense, TimeDistributed
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
import pandas as pd
from sklearn.model_selection import train_test_split
import json
import os
from google.colab import files

nltk.download('punkt')
print("Entorno listo!")

# === DESCARGA Y EXTRACCIÓN AUTOMÁTICA DE ARCHIVOS MONOLINGÜES ===
import urllib.request
import gzip
import shutil
import os
import urllib.request
import os

# REEMPLAZA ESTOS ENLACES CON TUS ENLACES REALES
ES_URL = "https://object.pouta.csc.fi/OPUS-QED/v2.0a/mono/es.txt.gz"
QUE_URL = "https://object.pouta.csc.fi/OPUS-QED/v2.0a/mono/que.txt.gz"

def descargar_y_extraer(url, nombre_salida):
    gz_path = f"{nombre_salida}.gz"
    txt_path = f"{nombre_salida}.txt"
    print(f"Descargando {gz_path}...")
    urllib.request.urlretrieve(url, gz_path)
    print(f"{gz_path} descargado correctamente.")
    print(f"Extrayendo {gz_path} a {txt_path}...")
    try:
        with gzip.open(gz_path, 'rb') as f_in:
            with open(txt_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        print(f"{txt_path} extraído correctamente.")
    except Exception as e:
        print(f"❌ Error al extraer {gz_path}: {e}")
        return
    os.remove(gz_path)
    print(f"{gz_path} eliminado.")
    assert os.path.exists(txt_path), f"¡Error! No se pudo crear {txt_path}"

# Procesar archivos
descargar_y_extraer(ES_URL, "es")
descargar_y_extraer(QUE_URL, "que")
print("✅ ¡Ambos archivos .txt descargados y extraídos correctamente!")

# === LIMPIEZA Y PREPROCESAMIENTO ===
def clean_text(text, lang):
    text = normalize('NFC', text.strip())
    if not text:
        return ""
    text = text.lower()
    punctuation = string.punctuation.replace("'", "").replace("-", "")
    text = re.sub(f"[{re.escape(punctuation)}]", "", text)
    text = re.sub(r'\s+', ' ', text).strip()
    if lang == 'es':
        text = '<start> ' + text + ' <end>'
    else:
        text = '<start> ' + text + ' <end>'
    return text

with open('es.txt', 'r', encoding='utf-8') as f:
    es_lines = f.readlines()
with open('que.txt', 'r', encoding='utf-8') as f:
    qu_lines = f.readlines()

min_lines = min(len(es_lines), len(qu_lines))
es_lines = es_lines[:min_lines]
qu_lines = qu_lines[:min_lines]

pairs = []
for es, qu in zip(es_lines, qu_lines):
    es_clean = clean_text(es, 'es')
    qu_clean = clean_text(qu, 'que')
    if es_clean.count(' ') > 3 and qu_clean.count(' ') > 3:
        pairs.append((es_clean, qu_clean))

print(f"Total de pares válidos: {len(pairs)}")

# --- Tokenización ---
es_tokenizer = Tokenizer(filters='')
qu_tokenizer = Tokenizer(filters='')
es_tokenizer.fit_on_texts([p[0] for p in pairs])
qu_tokenizer.fit_on_texts([p[1] for p in pairs])

vocab_es = len(es_tokenizer.word_index) + 1
vocab_qu = len(qu_tokenizer.word_index) + 1

encoder_input = es_tokenizer.texts_to_sequences([p[0] for p in pairs])
decoder_input = qu_tokenizer.texts_to_sequences([p[1].replace('<end>', '') + ' <end>' for p in pairs])
decoder_target = qu_tokenizer.texts_to_sequences([p[1] for p in pairs])

max_len_es = max(len(seq) for seq in encoder_input)
max_len_qu = max(len(seq) for seq in decoder_target)

encoder_input = pad_sequences(encoder_input, maxlen=max_len_es, padding='post')
decoder_input = pad_sequences(decoder_input, maxlen=max_len_qu, padding='post')
decoder_target = pad_sequences(decoder_target, maxlen=max_len_qu, padding='post')

X_train_enc, X_test_enc, X_train_dec, X_test_dec, y_train, y_test = train_test_split(
    encoder_input, decoder_input, decoder_target, test_size=0.2, random_state=42)

# --- RNN simple ---
encoder_inputs = Input(shape=(max_len_es,))
enc_emb = Embedding(vocab_es, 256, mask_zero=True)(encoder_inputs)
encoder_rnn = SimpleRNN(512, return_state=True)
encoder_outputs, state_h = encoder_rnn(enc_emb)
encoder_states = [state_h]

decoder_inputs = Input(shape=(max_len_qu,))
dec_emb_layer = Embedding(vocab_qu, 256, mask_zero=True)
dec_emb = dec_emb_layer(decoder_inputs)
decoder_rnn = SimpleRNN(512, return_sequences=True, return_state=True)
decoder_outputs, _ = decoder_rnn(dec_emb, initial_state=encoder_states)
decoder_dense = TimeDistributed(Dense(vocab_qu, activation='softmax'))
decoder_outputs = decoder_dense(decoder_outputs)

model_rnn = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history_rnn = model_rnn.fit(
    [X_train_enc, X_train_dec], y_train[..., np.newaxis],
    validation_data=([X_test_enc, X_test_dec], y_test[..., np.newaxis]),
    batch_size=32,
    epochs=30,
    verbose=1
)
model_rnn.save('rnn_simple.h5')

# --- LSTM ---
encoder_inputs_l = Input(shape=(max_len_es,))
enc_emb_l = Embedding(vocab_es, 256, mask_zero=True)(encoder_inputs_l)
encoder_lstm = LSTM(512, return_state=True)
encoder_outputs_l, state_h_l, state_c_l = encoder_lstm(enc_emb_l)
encoder_states_l = [state_h_l, state_c_l]

decoder_inputs_l = Input(shape=(max_len_qu,))
dec_emb_l = dec_emb_layer(decoder_inputs_l)
decoder_lstm = LSTM(512, return_sequences=True, return_state=True)
decoder_outputs_l, _, _ = decoder_lstm(dec_emb_l, initial_state=encoder_states_l)
decoder_outputs_l = decoder_dense(decoder_outputs_l)

model_lstm = Model([encoder_inputs_l, decoder_inputs_l], decoder_outputs_l)
model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history_lstm = model_lstm.fit(
    [X_train_enc, X_train_dec], y_train[..., np.newaxis],
    validation_data=([X_test_enc, X_test_dec], y_test[..., np.newaxis]),
    batch_size=32,
    epochs=30,
    verbose=1
)
model_lstm.save('lstm_model.h5')

# --- Inferencia y BLEU ---
def translate(sentence, model, enc_tok, dec_tok, max_enc, max_dec):
    seq = enc_tok.texts_to_sequences([sentence])
    seq = pad_sequences(seq, maxlen=max_enc, padding='post')
    if 'SimpleRNN' in str(model.layers):
        states = model.layers[2].states[0]
        states = model.predict([seq, np.zeros((1, max_dec))], verbose=0)[1]
    else:
        states = [model.predict([seq, np.zeros((1, max_dec))], verbose=0)[1],
                  model.predict([seq, np.zeros((1, max_dec))], verbose=0)[2]]

    target_seq = np.zeros((1, max_dec))
    target_seq[0, 0] = dec_tok.word_index['<start>']
    output = []
    for i in range(1, max_dec):
        if 'SimpleRNN' in str(model.layers):
            preds, h = model.predict([seq, target_seq], verbose=0)
            states = [h]
        else:
            preds, h, c = model.predict([seq, target_seq], verbose=0)
            states = [h, c]
        idx = np.argmax(preds[0, i-1, :])
        if idx == dec_tok.word_index.get('<end>', 0):
            break
        word = dec_tok.index_word.get(idx, '')
        output.append(word)
        target_seq[0, i] = idx
    return ' '.join(output)

smoothie = SmoothingFunction().method4
bleu_rnn, bleu_lstm = [], []

test_pairs = [(es_tokenizer.sequences_to_texts([x])[0].replace('<start>', '').replace('<end>', '').strip(),
               qu_tokenizer.sequences_to_texts([y])[0].replace('<start>', '').replace('<end>', '').strip())
              for x, y in zip(X_test_enc[:50], y_test[:50])]

for es, qu in test_pairs:
    pred_rnn = translate(es, model_rnn, es_tokenizer, qu_tokenizer, max_len_es, max_len_qu)
    pred_lstm = translate(es, model_lstm, es_tokenizer, qu_tokenizer, max_len_es, max_len_qu)
    ref = qu.split()
    bleu_rnn.append(sentence_bleu([ref], pred_rnn.split(), smoothing_function=smoothie))
    bleu_lstm.append(sentence_bleu([ref], pred_lstm.split(), smoothing_function=smoothie))

print(f"BLEU RNN: {np.mean(bleu_rnn):.4f}")
print(f"BLEU LSTM: {np.mean(bleu_lstm):.4f}")

# --- Gráficos ---
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history_rnn.history['loss'], label='RNN Train')
plt.plot(history_rnn.history['val_loss'], label='RNN Val')
plt.plot(history_lstm.history['loss'], label='LSTM Train')
plt.plot(history_lstm.history['val_loss'], label='LSTM Val')
plt.title('Pérdida')
plt.legend()
plt.subplot(1,2,2)
plt.plot(history_rnn.history['accuracy'], label='RNN Train')
plt.plot(history_rnn.history['val_accuracy'], label='RNN Val')
plt.plot(history_lstm.history['accuracy'], label='LSTM Train')
plt.plot(history_lstm.history['val_accuracy'], label='LSTM Val')
plt.title('Precisión')
plt.legend()
plt.show()

# --- Demo interactivo (consola) ---
from IPython.display import clear_output
import time
def translate_interactive(sentence, model, enc_tok, dec_tok, max_enc, max_dec, model_name):
    seq = enc_tok.texts_to_sequences([sentence])
    seq = pad_sequences(seq, maxlen=max_enc, padding='post')
    if 'SimpleRNN' in str(model.layers):
        _, state = model.layers[2](model.layers[1](seq))
        states = [state]
    else:
        _, state_h, state_c = model.layers[2](model.layers[1](seq))
        states = [state_h, state_c]
    target_seq = np.zeros((1, max_dec))
    target_seq[0, 0] = dec_tok.word_index.get('<start>', 1)
    output = []
    for i in range(1, max_dec):
        if 'SimpleRNN' in str(model.layers):
            preds, h = model.layers[-3](model.layers[-4](target_seq, initial_state=states))
            states = [h]
        else:
            preds, h, c = model.layers[-3](model.layers[-4](target_seq, initial_state=states))
            states = [h, c]
        idx = np.argmax(preds[0, i-1, :])
        if idx == dec_tok.word_index.get('<end>', 0):
            break
        word = dec_tok.index_word.get(idx, '')
        if word:
            output.append(word)
        target_seq[0, i] = idx
    return ' '.join(output)

print("TRADUCTOR ESPAÑOL → QUECHUA (RNN vs LSTM)")
print("Escribe 'salir' para terminar.\n")
while True:
    try:
        clear_output(wait=True)
        print("TRADUCTOR ESPAÑOL → QUECHUA")
        print("="*50)
        sentence = input("\nEspañol: ").strip()
        if sentence.lower() in ['salir', 'exit', 'quit']:
            print("¡Hasta luego!")
            break
        if not sentence:
            print("Por favor, escribe algo.")
            time.sleep(1)
            continue
        print("\nTraduciendo...")
        time.sleep(1)
        trad_rnn = translate_interactive(sentence, model_rnn, es_tokenizer, qu_tokenizer, max_len_es, max_len_qu, "RNN")
        trad_lstm = translate_interactive(sentence, model_lstm, es_tokenizer, qu_tokenizer, max_len_es, max_len_qu, "LSTM")
        print("\nRESULTADOS:")
        print(f"   RNN : {trad_rnn}")
        print(f"  LSTM : {trad_lstm}")
        print("\n" + "-"*50)
        input("Presiona Enter para traducir otra frase...")
    except Exception as e:
        print(f"Error: {e}")
        time.sleep(2)
// ----------------- FIN RNN.py -----------------
        </pre>
      </details>

      <div style="margin-top:16px;display:flex;gap:8px;">
        <button class="btn" onclick="downloadPy()">Descargar .py</button>
        <button class="btn ghost" onclick="copyCode()">Copiar al portapapeles</button>
      </div>

      <p class="muted" style="margin-top:12px">Sugerencia: ejecutar en Google Colab o entorno con TensorFlow compatible. Reemplazar URLs si hacen falta y validar encoding UTF-8.</p>
    </section>

    <section id="conclusiones" class="card" style="margin-top:18px;">
      <h3>Conclusiones</h3>
      <ul class="muted">
        <li>LSTM es la arquitectura recomendada para este dominio por su capacidad de modelar dependencias largas; la diferencia cuantitativa en BLEU y accuracy lo confirma.</li>
        <li>El prototipo es válido para demostración y como material educativo; para producción se requiere ampliación y curación del corpus, tokenización subword y modelos con atención o Transformer.</li>
        <li>El proyecto contribuye a accesibilidad tecnológica para lenguas minorizadas, con potencial educativo en zonas con recursos limitados.</li>
      </ul>
    </section>

    <footer>
      <div class="muted">Generado automáticamente — Contenido: informe + código · Universidad Andina del Cusco · 2025</div>
    </footer>
  </div>

  <script>
    // Extraer contenido del <pre> para operaciones JS (download / copy)
    function getCodeText(){
      const pre = document.getElementById('src');
      return pre ? pre.innerText : '';
    }

    function downloadPy(){
      const text = getCodeText();
      const blob = new Blob([text], {type: 'text/x-python;charset=utf-8'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'RNN.py';
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
    }

    async function copyCode(){
      const text = getCodeText();
      try{
        await navigator.clipboard.writeText(text);
        alert('Código copiado al portapapeles.');
      }catch(e){
        alert('Error al copiar. Seleccione manualmente el código.');
      }
    }

    function toggleAll(){
      const d = document.getElementById('codeblock');
      if(d) d.open = !d.open;
    }

    // smooth scroll for toc anchors
    document.querySelectorAll('.toc a').forEach(a=>{
      a.addEventListener('click', e=>{
        e.preventDefault();
        const id = a.getAttribute('href').slice(1);
        const el = document.getElementById(id);
        if(el) el.scrollIntoView({behavior:'smooth', block:'start'});
      });
    });
  </script>
</body>
</html>
